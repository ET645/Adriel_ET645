{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":["# Modules\n","\n","# General functionality and file manipulation\n","import os\n","from datetime import datetime\n","\n","# Data Processing\n","import pandas as pd\n","import numpy as np\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, utils\n","from sklearn.model_selection import train_test_split\n","\n","# Neural Network\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch import optim\n","\n","## Plotting data\n","%matplotlib inline\n","%config InlineBackend.figure_format = 'retina'\n","import matplotlib.pyplot as plt"],"execution_count":46,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["# MNIST - Classical MLP\n","\n","Implementation in Pytorch of MLP Neural Network."]},{"metadata":{},"cell_type":"markdown","source":["## (Quick) EDA"]},{"metadata":{"trusted":true},"cell_type":"code","source":["df = pd.read_csv('data/train.csv')"],"execution_count":47,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["print(f'How many obs: {df.shape}')\n","print(df.dtypes)\n","print(df.head())\n","print(df.columns)"],"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["How many obs: (42000, 785)\nlabel       int64\npixel0      int64\npixel1      int64\npixel2      int64\npixel3      int64\n            ...  \npixel779    int64\npixel780    int64\npixel781    int64\npixel782    int64\npixel783    int64\nLength: 785, dtype: object\n<bound method NDFrame.describe of        label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n0          1       0       0       0       0       0       0       0       0   \n1          0       0       0       0       0       0       0       0       0   \n2          1       0       0       0       0       0       0       0       0   \n3          4       0       0       0       0       0       0       0       0   \n4          0       0       0       0       0       0       0       0       0   \n...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n41995      0       0       0       0       0       0       0       0       0   \n41996      1       0       0       0       0       0       0       0       0   \n41997      7       0       0       0       0       0       0       0       0   \n41998      6       0       0       0       0       0       0       0       0   \n41999      9       0       0       0       0       0       0       0       0   \n\n       pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  \\\n0           0  ...         0         0         0         0         0   \n1           0  ...         0         0         0         0         0   \n2           0  ...         0         0         0         0         0   \n3           0  ...         0         0         0         0         0   \n4           0  ...         0         0         0         0         0   \n...       ...  ...       ...       ...       ...       ...       ...   \n41995       0  ...         0         0         0         0         0   \n41996       0  ...         0         0         0         0         0   \n41997       0  ...         0         0         0         0         0   \n41998       0  ...         0         0         0         0         0   \n41999       0  ...         0         0         0         0         0   \n\n       pixel779  pixel780  pixel781  pixel782  pixel783  \n0             0         0         0         0         0  \n1             0         0         0         0         0  \n2             0         0         0         0         0  \n3             0         0         0         0         0  \n4             0         0         0         0         0  \n...         ...       ...       ...       ...       ...  \n41995         0         0         0         0         0  \n41996         0         0         0         0         0  \n41997         0         0         0         0         0  \n41998         0         0         0         0         0  \n41999         0         0         0         0         0  \n\n[42000 rows x 785 columns]>\n"]}]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["True\n"]}],"source":["a = df.iloc[0, :]\n","print('label' in a.index.tolist())"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["(784,)\n(28, 28)\n"]},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7efe703c6370>"]},"metadata":{},"execution_count":50},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"image/png":{"width":251,"height":248},"needs_background":"light"}}],"source":["ex = df.iloc[100, 1:].to_numpy()\n","print(ex.shape)\n","ex.shape = (np.sqrt(784).astype('int'), -1) \n","print(ex.shape)\n","plt.imshow(ex)"]},{"metadata":{},"cell_type":"markdown","source":["## Data Processing"]},{"metadata":{},"cell_type":"markdown","source":["### DataLoader and Transformations"]},{"metadata":{"trusted":true},"cell_type":"code","source":["class NumberImagePixel(Dataset):\n","    \n","    def __init__(self, df, transform=None):\n","        \n","        self.df = df\n","        self.transform = transform\n","        self.predict_data = not ('label' in df.columns.tolist())\n","    \n","    def __len__(self):\n","        return len(self.df)\n","    \n","    def __getitem__(self, idx):\n","        if torch.is_tensor(idx):\n","            idx = idx.tolist()\n","        \n","        row = self.df.iloc[idx]\n","\n","        if self.predict_data:\n","            label = -1\n","            features = row.to_numpy()\n","        else:\n","            label = row['label']\n","            features = row.drop(labels='label').to_numpy()\n","            \n","        row = {'label': label, 'features': features}\n","        \n","        if self.transform:\n","            row = self.transform(row)\n","        \n","        return row \n","        \n","        "],"execution_count":52,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["class Normalization(object):\n","    \"\"\" Normalise by mean and stdv\"\"\"\n","    \n","    def __call__(self, sample):\n","        label, feat = sample['label'], sample['features']\n","        \n","        feat = feat/255 #(feat - np.mean(feat))/np.std(feat)\n","        \n","        return {'label': label,\n","               'features': feat}\n","\n","\n","class ToTensor(object):\n","    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n","\n","    def __call__(self, sample):\n","        label, features = sample['label'], sample['features']\n","\n","        # If data is to be predicted.\n","        if label == -1:\n","            return {'label': label,\n","               'features': torch.from_numpy(features).type(torch.FloatTensor)}\n","\n","        return {'label': torch.from_numpy(np.array(label)).type(torch.LongTensor),\n","               'features': torch.from_numpy(features).type(torch.FloatTensor)}"],"execution_count":53,"outputs":[]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[],"source":["def make_dataloader(df, batch_size):\n","    data = NumberImagePixel(df=df,\n","                            transform=transforms.Compose([Normalization(),\n","                                                          ToTensor()]))\n","    dataloader = DataLoader(data, batch_size=batch_size,\n","                            shuffle=True, num_workers=0)\n","    return dataloader"]},{"metadata":{"trusted":true},"cell_type":"code","source":["batch_size = 128\n","df_train = pd.read_csv('data/train.csv')\n","X_train, X_validation, y_train, y_validation = train_test_split(df_train[[col for col in df.columns if col != 'label']],\n","                                                                df_train['label'],\n","                                                                test_size = 0.1)\n","\n","X_train['label'] = y_train\n","X_validation['label'] = y_validation\n","\n","\n","df_train = X_train\n","df_validation = X_validation\n","df_test = pd.read_csv('data/test.csv')\n","print('label' in df_train.columns.tolist())\n","\n","dataloader = {}\n","names = ['train', 'validation', 'test']\n","for idx, df in enumerate([df_train, df_validation, df_test]):\n","    dataloader.update({names[idx]: make_dataloader(df, batch_size)})"],"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n"]}]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["{'label': tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n        -1, -1]), 'features': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.]])}\nlabel torch.Size([128])\nfeat torch.Size([128, 784])\n"]}],"source":["for data in iter(dataloader['test']):\n","    print(data)\n","    print(f'label {data[\"label\"].shape}')\n","    print(f'feat {data[\"features\"].shape}')\n","    break"]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["{'label': tensor([3, 9, 3, 3, 2, 6, 7, 4, 7, 7, 5, 6, 7, 0, 9, 2, 7, 9, 8, 2, 3, 7, 0, 2,\n        6, 2, 5, 1, 7, 7, 2, 7, 7, 7, 0, 8, 2, 5, 7, 7, 8, 7, 8, 1, 1, 7, 3, 6,\n        7, 8, 5, 0, 5, 9, 0, 1, 1, 3, 1, 6, 9, 6, 7, 2, 4, 7, 4, 3, 1, 9, 4, 6,\n        0, 8, 3, 2, 7, 1, 3, 9, 1, 8, 9, 0, 0, 0, 7, 1, 9, 7, 5, 0, 9, 7, 2, 5,\n        3, 0, 2, 6, 0, 0, 6, 7, 0, 6, 7, 5, 7, 6, 9, 5, 2, 8, 0, 8, 8, 1, 7, 4,\n        6, 9, 0, 4, 2, 8, 0, 7]), 'features': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.]])}\nlabel torch.Size([128])\nfeat torch.Size([128, 784])\n"]}],"source":["for data in iter(dataloader['train']):\n","    print(data)\n","    print(f'label {data[\"label\"].shape}')\n","    print(f'feat {data[\"features\"].shape}')\n","    break"]},{"metadata":{},"cell_type":"markdown","source":["## Neural Network"]},{"source":["### Neural Net. Architecture"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[],"source":["class MultiClassifier(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        # 5 Hidden Layer Network\n","        self.fc1 = nn.Linear(28*28, 512)\n","        self.fc2 = nn.Linear(512, 256)\n","        self.fc3 = nn.Linear(256, 128)\n","        self.fc4 = nn.Linear(128, 64)\n","        self.fc5 = nn.Linear(64, 10)\n","        \n","        # Dropout module with 0.2 probbability\n","        self.dropout = nn.Dropout(p=0.2)\n","        # Add softmax on output layer\n","        self.log_softmax = F.log_softmax\n","        \n","    def forward(self, x):\n","        x = self.dropout(F.relu(self.fc1(x)))\n","        x = self.dropout(F.relu(self.fc2(x)))\n","        x = self.dropout(F.relu(self.fc3(x)))\n","        x = self.dropout(F.relu(self.fc4(x)))\n","        \n","        x = self.log_softmax(self.fc5(x), dim=1)\n","        \n","        return x"]},{"source":["### Training the model"],"cell_type":"markdown","metadata":{}},{"metadata":{"trusted":true},"cell_type":"code","source":["def train_model(model, dataloader,\n","                criterion, optimizer,\n","                n_epoch=10, path_to_save='model.pt', \n","                print_every=None):\n","    \"\"\"\n","    Train our Neural Network with data and return the trained model,\n","    the plot diagnostics and also save the model in the path_to_save.\n","    \n","    Args:\n","    dataloader (dict): contains train dataloader and validation dataloader.\n","    path_to_save (str): path to save the model parameters in the .pt format.\n","    \n","    Returns:\n","    model: model trained with model.eval() = True.\n","    \"\"\"\n","    # Checking if GPU is available\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    cpu_or_gpu = ('GPU' if torch.cuda.is_available() else 'CPU')\n","    print(f\"Running training on {cpu_or_gpu}\")\n","    model = model.to(device)\n","\n","    # initialize tracker for minimum validation loss\n","    valid_loss_min = np.Inf # set initial \"min\" to +infinity\n","\n","    train_losses = []\n","    valid_losses = []\n","    \n","    if print_every is None:\n","        print_every = int(n_epoch * 0.1) + 1\n","        \n","    for epoch in range(1, n_epoch + 1):\n","        \n","        train_loss = 0.0\n","        valid_loss = 0.0\n","\n","        ###################\n","        # train the model #\n","        ###################\n","        # prep model for training\n","        model.train() \n","        print('\\n Training Loss...')\n","        turn = 0\n","        for data in dataloader['train']:\n","\n","            x_train = data['features'].to(device)\n","            y_train = data['label'].to(device)\n","\n","            # clear the gradients of all optimized variables\n","            optimizer.zero_grad()\n","            # forward pass: compute predicted outputs by passing inputs to the model\n","            output = model(x_train) \n","            # calculate the loss\n","            loss = criterion(output, y_train)\n","            # backward pass: compute gradient of the loss with respect to model parameters\n","            loss.backward()\n","            # perform a single optimization step (parameter update)\n","            optimizer.step()\n","            # update running training loss\n","            train_loss += loss.item()\n","            \n","            turn += 1\n","            if turn % print_every == 0:\n","                print(f'Turn {turn}: {train_loss}')\n","\n","\n","        ######################    \n","        # validate the model #\n","        ######################\n","        model.eval() # prep model for evaluation\n","        print(\"\\n Validation Loss...\")\n","        turn = 0\n","        for data in dataloader['validation']:\n","            x_validation = data['features'].to(device)\n","            y_validation = data['label'].to(device)\n","\n","            # forward pass: compute predicted outputs by passing inputs to the model\n","            output = model(x_validation) # log_ps\n","            # calculate the loss\n","            loss = criterion(output, y_validation) \n","            # update running validation loss \n","            valid_loss += loss.item()\n","\n","            turn += 1\n","            if turn % print_every == 0:\n","                print(f'Turn {turn}: {train_loss} \\n')\n","\n","        # print training/validation statistics \n","        # calculate average loss over an epoch\n","        train_loss = train_loss/len(dataloader['train'])\n","        train_losses.append(train_loss)\n","        valid_loss = valid_loss/len(dataloader['validation'])\n","        valid_losses.append(valid_loss)\n","\n","        print(f\"\"\"\n","            Epoch: {epoch}\n","            \\tTraining Loss: {round(train_loss, 6)}\n","            \\tValidation Loss: {round(valid_loss, 6)}\n","            \"\"\")\n","\n","        # save model if validation loss has decreased\n","        if valid_loss < valid_loss_min:\n","            print(f'Validation loss decreased \\\n","                ({round(valid_loss_min,6)} --> {round(valid_loss,6)}).\\\n","                    Saving model ...')\n","            torch.save(model.state_dict(), path_to_save)\n","            valid_loss_min = valid_loss\n","    \n","    # Plotting train and validation losses.\n","    plt.plot(train_losses, label='Training loss')\n","    plt.plot(valid_losses, label='Validation loss')\n","    plt.legend(frameon=False)\n","    \n","    return model"],"execution_count":59,"outputs":[]},{"cell_type":"code","execution_count":45,"metadata":{"tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":["Running training on cpu\n","\n"," Training Loss...\n","Turn 50: 63.40152549743652\n","Turn 100: 87.43031507730484\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-45-3b3ac65e0df2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0015\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-44-dcb327006f60>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloader, criterion, optimizer, n_epoch, path_to_save, print_every)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n Training Loss...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mturn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/Documents/Adriel_ET645/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/Documents/Adriel_ET645/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/Documents/Adriel_ET645/venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/Documents/Adriel_ET645/venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-37-d250c998c557>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/Documents/Adriel_ET645/venv/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/Documents/Adriel_ET645/venv/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1501\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1503\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1505\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/Documents/Adriel_ET645/venv/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_ixs\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   2945\u001b[0m         \u001b[0;31m# irow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2946\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2947\u001b[0;31m             \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_xs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2949\u001b[0m             \u001b[0;31m# if we are a copy, mark as such\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/Documents/Adriel_ET645/venv/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mfast_xs\u001b[0;34m(self, loc)\u001b[0m\n\u001b[1;32m    966\u001b[0m             \u001b[0;31m# result[blk.mgr_locs] = blk._slice((slice(None), loc))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExtensionDtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/Documents/Adriel_ET645/venv/lib/python3.8/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36miget\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0miget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["model = MultiClassifier()\n","# Define our loss function\n","criterion = nn.NLLLoss()\n","# Define the optimier\n","optimizer = optim.Adam(model.parameters(), lr=0.0015)\n","\n","model = train_model(model=model, n_epoch = 10, dataloader=dataloader,criterion=criterion, optimizer=optimizer, print_every=50)"]},{"source":["### Predict new dataset"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":420,"metadata":{"tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":["Prob tensor([[1.0000]], device='cuda:0'), \n Class: tensor([[3]], device='cuda:0')\n(28, 28)\n"]},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"image/png":{"width":251,"height":248},"needs_background":"light"}}],"source":["def predict(model, data):\n","    model.eval() # prepare model for evaluation\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    # To speed up calculations, forget the gradients, etc.\n","    with torch.no_grad():\n","        x_cpu = data\n","        x = data.to(device)\n","        output = model(x)\n","        output = torch.exp(output)\n","        top_p, top_class = output.topk(1, dim=1)\n","        print(f'Prob {top_p}, \\n Class: {top_class}')\n","        x = x_cpu.view(np.sqrt(784).astype('int'), -1)\n","        x = x.numpy() * 300\n","        print(x.shape)\n","        plt.imshow(x)\n","        plt.show()\n","\n","for data in dataloader['test']:\n","    data = data['features'][0:1,]\n","    predict(model, data)\n","    break"]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.8.5-final","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}